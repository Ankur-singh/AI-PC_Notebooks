<!doctype html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Chatbot in the Browser</title>
    </head>
    <body>
        <div id="loading-progress"></div>
        <div style="margin: 10px;">
            <textarea id="chat-input" placeholder="Type a message..." rows="2"></textarea>
            <button id="send-btn">Send</button>
        </div>
        <div id="message-container"></div>
        <!-- External JavaScript File -->
        <script type="module">
            import * as webllm from "https://esm.run/@mlc-ai/web-llm";
            
            // DOM Selectors
            const messageContainer = document.getElementById("message-container");
            const sendButton = document.getElementById("send-btn");
            const chatInput = document.getElementById("chat-input");
            const loadingProgress = document.getElementById("loading-progress");

            // Initialize with a progress callback
            const initProgressCallback = (progress) => {
                loadingProgress.textContent = `Model loading progress: ${progress.text}`;
                console.log("Model loading progress:", progress);
            };

            // Create engine instance
            const engine = await webllm.CreateMLCEngine("Llama-3.2-1B-Instruct-q4f32_1-MLC", { initProgressCallback });

            // Update chat UI with new messages
            function updateChatUI(message, role) {
                const messageDiv = document.createElement("div");
                messageDiv.textContent = `${role}: ${message}`;
                messageContainer.appendChild(messageDiv);
            }

            // Stream message generation from the engine
            async function streamGeneration(messages) {
                const chunks = await engine.chat.completions.create({
                    messages,
                    temperature: 1,
                    stream: true,
                    stream_options: { include_usage: true },
                });

                let reply = "AI: ";
                for await (const chunk of chunks) {
                    reply += chunk.choices[0]?.delta.content || "";
                    messageContainer.innerHTML = reply;
                    if (chunk.usage) {
                        console.log(chunk.usage); // only last chunk has usage
                    }
                }

                const fullReply = await engine.getMessage();
                console.log(fullReply);
            }

            // Send a new message
            function onSend() {
                if (chatInput.value.trim() !== "") {
                    sendButton.disabled = true;

                    // User message
                    const userMessage = { role: "user", content: chatInput.value };

                    // Clear input field
                    chatInput.value = "";

                    // Generate response
                    const messages = [
                        { role: "system", content: "You are a helpful AI assistant." },
                        userMessage
                    ];
                    streamGeneration(messages).then(() => {
                        sendButton.disabled = false;
                    });
                }
            }

            // Event listener for send button
            sendButton.addEventListener("click", onSend);
        </script>
    </body>
</html>
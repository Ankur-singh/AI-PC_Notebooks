<!doctype html>
<html lang="en">
    <head></head>
    <body>
        <h1 style="text-align: center;">WebLLM Chat Bot</h1>
        <p style="text-align: center;">Completion with the LLM model</p>
        <p style="text-align: center;">Open the console to see the response</p>
        <!-- External JavaScript File -->
        <script type="module">
            // Source: https://webllm.mlc.ai/docs/user/basic_usage.html#chat-completion
            import * as webllm from "https://esm.run/@mlc-ai/web-llm";

            // Initialize with a progress callback
            const initProgressCallback = (progress) => {
                console.log("Model loading progress:", progress);
            };


            // Using CreateMLCEngine
            const engine = await webllm.CreateMLCEngine("Llama-3.2-1B-Instruct-q4f32_1-MLC", { initProgressCallback });

            const messages = [
                { role: "system", content: "You are a helpful AI assistant." },
                { role: "user", content: "Hello!" }
            ];

            const reply = await engine.chat.completions.create({
                messages,
            });

            console.log(reply.choices[0].message);
            console.log(reply.usage);
        </script>
    </body>
</html>
